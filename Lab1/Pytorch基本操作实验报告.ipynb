{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b57686b-7ac8-4897-bf76-3d982b1ff8da",
   "metadata": {},
   "source": [
    "![school-logo](../images/school_logo.png)\n",
    "\n",
    "<h1><center>æœ¬ç§‘ç”Ÿã€Šæ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹<br>å®éªŒæŠ¥å‘Š</center></h1>\n",
    "<div style=\"text-align: center;\">\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">è¯¾ç¨‹åç§°</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">æ·±åº¦å­¦ä¹ </span></div>\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">å®éªŒé¢˜ç›®</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">PytorchåŸºæœ¬æ“ä½œ</span></div>\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">å­¦å·</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">21281280</span></div>\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">å§“å</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">æŸ¯åŠ²å¸†</span></div>\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">ç­çº§</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">ç‰©è”ç½‘2101ç­</span></div>\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">æŒ‡å¯¼è€å¸ˆ</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">å¼ æ·³æ°</span></div>\n",
    "    <div><span style=\"display: inline-block; width: 65px; text-align: center;\">æŠ¥å‘Šæ—¥æœŸ</span><span style=\"display: inline-block; width: 25px;\">:</span><span style=\"display: inline-block; width: 210px; font-weight: bold; text-align: left;\">2023å¹´10æœˆ9æ—¥</span></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24aa17e-faf9-4d69-9eae-43159116b56f",
   "metadata": {},
   "source": [
    "å®éªŒç¯å¢ƒï¼š\n",
    "- OSï¼šUbuntu 22.04 å†…æ ¸ç‰ˆæœ¬ 6.2.0-34-generic\n",
    "- CPUï¼š12th Gen Intel(R) Core(TM) i7-12700H\n",
    "- GPUï¼šNVIDIA GeForce RTX 3070 Ti Laptop\n",
    "- cuda: 12.2\n",
    "- conda: miniconda 23.9.0\n",
    "- pythonï¼š3.10.13\n",
    "- pytorchï¼š2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4e12268-bad4-44c4-92d5-883624d93e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f0ce5-d613-425b-807c-78115632cd80",
   "metadata": {},
   "source": [
    "å¼•ç”¨ç›¸å…³åº“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a43d35-56ac-4ade-995d-1c6fcbcd1262",
   "metadata": {},
   "source": [
    "# ä¸€ã€PytorchåŸºæœ¬æ“ä½œè€ƒå¯Ÿ\n",
    "## é¢˜ç›®2\n",
    "**ä½¿ç”¨ ğ“ğğ§ğ¬ğ¨ğ« åˆå§‹åŒ–ä¸€ä¸ª ğŸÃ—ğŸ‘ çš„çŸ©é˜µ ğ‘´ å’Œä¸€ä¸ª ğŸÃ—ğŸ çš„çŸ©é˜µ ğ‘µï¼Œå¯¹ä¸¤çŸ©é˜µè¿›è¡Œå‡æ³•æ“ä½œï¼ˆè¦æ±‚å®ç°ä¸‰ç§ä¸åŒçš„å½¢å¼ï¼‰ï¼Œç»™å‡ºç»“æœå¹¶åˆ†æä¸‰ç§æ–¹å¼çš„ä¸åŒï¼ˆå¦‚æœå‡ºç°æŠ¥é”™ï¼Œåˆ†ææŠ¥é”™çš„åŸå› ï¼‰ï¼ŒåŒæ—¶éœ€è¦æŒ‡å‡ºåœ¨è®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ea46db-cf49-436c-9b5b-c6562d0da9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–¹æ³•1çš„ç»“æœ:\n",
      "tensor([[-3, -2, -1],\n",
      "        [-4, -3, -2]])\n",
      "æ–¹æ³•2çš„ç»“æœ:\n",
      "tensor([[-3, -2, -1],\n",
      "        [-4, -3, -2]])\n",
      "æ–¹æ³•3çš„ç»“æœ:\n",
      "tensor([[-3, -2, -1],\n",
      "        [-4, -3, -2]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3]])\n",
    "\n",
    "B = torch.tensor([[4],\n",
    "                  [5]])\n",
    "\n",
    "# æ–¹æ³•1: ä½¿ç”¨PyTorchçš„å‡æ³•æ“ä½œç¬¦\n",
    "result1 = A - B\n",
    "\n",
    "# æ–¹æ³•2: ä½¿ç”¨PyTorchçš„subå‡½æ•°\n",
    "result2 = torch.sub(A, B)\n",
    "\n",
    "# æ–¹æ³•3: æ‰‹åŠ¨å®ç°å¹¿æ’­æœºåˆ¶å¹¶ä½œå·®\n",
    "def my_sub(a:torch.Tensor, b:torch.Tensor):\n",
    "    if not ((a.size(0) == 1 and b.size(1) == 1) or (a.size(1) == 1 and b.size(0) == 1)):\n",
    "        raise ValueError(\"è¾“å…¥çš„å¼ é‡å¤§å°æ— æ³•æ»¡è¶³å¹¿æ’­æœºåˆ¶çš„æ¡ä»¶ã€‚\")\n",
    "    else:\n",
    "        target_shape = torch.Size([max(A.size(0), B.size(0)), max(A.size(1), B.size(1))])\n",
    "        A_broadcasted = A.expand(target_shape)\n",
    "        B_broadcasted = B.expand(target_shape)\n",
    "        result = torch.zeros(target_shape, dtype=torch.int64).to(device=A_broadcasted.device)\n",
    "        for i in range(target_shape[0]):\n",
    "            for j in range(target_shape[1]):\n",
    "                result[i, j] = A_broadcasted[i, j] - B_broadcasted[i, j]\n",
    "        return result\n",
    "\n",
    "result3 = my_sub(A, B)\n",
    "\n",
    "print(\"æ–¹æ³•1çš„ç»“æœ:\")\n",
    "print(result1)\n",
    "print(\"æ–¹æ³•2çš„ç»“æœ:\")\n",
    "print(result2)\n",
    "print(\"æ–¹æ³•3çš„ç»“æœ:\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489a3ad-f6ff-4561-bb26-e02654090b98",
   "metadata": {},
   "source": [
    "## é¢˜ç›®2\n",
    "1. **åˆ©ç”¨Tensoråˆ›å»ºä¸¤ä¸ªå¤§å°åˆ†åˆ«$3\\times 2$å’Œ$4\\times 2$çš„éšæœºæ•°çŸ©é˜µPå’ŒQï¼Œè¦æ±‚æœä»å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®0.01ä¸ºçš„æ­£æ€åˆ†å¸ƒï¼›**\n",
    "2. **å¯¹ç¬¬äºŒæ­¥å¾—åˆ°çš„çŸ©é˜µQè¿›è¡Œå½¢çŠ¶å˜æ¢å¾—åˆ°Qçš„è½¬ç½®Q^Tï¼›**\n",
    "3. **å¯¹ä¸Šè¿°å¾—åˆ°çš„çŸ©é˜µPå’ŒçŸ©é˜µQ^Tæ±‚çŸ©é˜µç›¸ä¹˜ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41e4ee02-1d05-4101-b3f0-477bac0277fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çŸ©é˜µ P:\n",
      "tensor([[-0.0094, -0.0073],\n",
      "        [-0.0087, -0.0008],\n",
      "        [-0.0012,  0.0103]])\n",
      "çŸ©é˜µ Q:\n",
      "tensor([[ 0.0094, -0.0126],\n",
      "        [-0.0082,  0.0005],\n",
      "        [-0.0079, -0.0101],\n",
      "        [-0.0002, -0.0161]])\n",
      "çŸ©é˜µ QT:\n",
      "tensor([[ 0.0094, -0.0082, -0.0079, -0.0002],\n",
      "        [-0.0126,  0.0005, -0.0101, -0.0161]])\n",
      "çŸ©é˜µç›¸ä¹˜çš„ç»“æœ:\n",
      "tensor([[ 4.8768e-06,  7.3478e-05,  1.4821e-04,  1.2020e-04],\n",
      "        [-7.1462e-05,  7.1558e-05,  7.7439e-05,  1.4915e-05],\n",
      "        [-1.4130e-04,  1.4922e-05, -9.4810e-05, -1.6629e-04]])\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "stddev = 0.01\n",
    "\n",
    "P = torch.normal(mean=mean, std=stddev, size=(3, 2))\n",
    "Q = torch.normal(mean=mean, std=stddev, size=(4, 2))\n",
    "\n",
    "print(\"çŸ©é˜µ P:\")\n",
    "print(P)\n",
    "print(\"çŸ©é˜µ Q:\")\n",
    "print(Q)\n",
    "\n",
    "# å¯¹çŸ©é˜µQè¿›è¡Œè½¬ç½®æ“ä½œï¼Œå¾—åˆ°çŸ©é˜µQçš„è½¬ç½®Q^T\n",
    "QT = Q.T\n",
    "print(\"çŸ©é˜µ QT:\")\n",
    "print(QT)\n",
    "\n",
    "# è®¡ç®—çŸ©é˜µPå’ŒçŸ©é˜µQ^Tçš„çŸ©é˜µç›¸ä¹˜\n",
    "result = torch.matmul(P, QT)\n",
    "print(\"çŸ©é˜µç›¸ä¹˜çš„ç»“æœ:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9cb6d-adde-4e08-b9f2-8c417abf4231",
   "metadata": {},
   "source": [
    "## é¢˜ç›®2\n",
    "**ç»™å®šå…¬å¼$ y_3=y_1+y_2=ğ‘¥^2+ğ‘¥^3$ï¼Œä¸”$x=1$ã€‚åˆ©ç”¨å­¦ä¹ æ‰€å¾—åˆ°çš„Tensorçš„ç›¸å…³çŸ¥è¯†ï¼Œæ±‚$y_3$å¯¹$x$çš„æ¢¯åº¦ï¼Œå³$\\frac{dy_3}{dx}$ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "951512cd-d915-4d04-959f-eb99d1971e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¢¯åº¦(dy_3/dx):  2.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y_1 = x ** 2\n",
    "with torch.no_grad():\n",
    "    y_2 = x ** 3\n",
    "\n",
    "y3 = y_1 + y_2\n",
    "\n",
    "y3.backward()\n",
    "\n",
    "print(\"æ¢¯åº¦(dy_3/dx): \", x.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269dbf6-889a-49eb-8094-1e588e1a6c30",
   "metadata": {},
   "source": [
    "# äºŒã€åŠ¨æ‰‹å®ç°logisticå›å½’\n",
    "## é¢˜ç›®1\n",
    "**è¦æ±‚åŠ¨æ‰‹ä»0å®ç° logistic å›å½’ï¼ˆåªå€ŸåŠ©Tensorå’ŒNumpyç›¸å…³çš„åº“ï¼‰åœ¨äººå·¥æ„é€ çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå¹¶ä»lossä»¥åŠè®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ç­‰å¤šä¸ªè§’åº¦å¯¹ç»“æœè¿›è¡Œåˆ†æï¼ˆå¯å€ŸåŠ©nn.BCELossæˆ–nn.BCEWithLogitsLossä½œä¸ºæŸå¤±å‡½æ•°ï¼Œä»é›¶å®ç°äºŒå…ƒäº¤å‰ç†µä¸ºé€‰ä½œï¼‰**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd12aa9-f187-4d88-8c59-af6d16107edb",
   "metadata": {},
   "source": [
    "ç»™å®šé¢„æµ‹æ¦‚ç‡$ \\left( \\hat{y} \\right) $å’Œç›®æ ‡æ ‡ç­¾$ \\left( y \\right)$ï¼ˆé€šå¸¸æ˜¯0æˆ–1ï¼‰ï¼ŒBCELossçš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n",
    "$$\n",
    " \\text{BCELoss}(\\hat{y}, y) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left(y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i)\\right) \n",
    "$$\n",
    "å…¶ä¸­ï¼Œ$\\left( N \\right) $æ˜¯æ ·æœ¬æ•°é‡ï¼Œ$\\left( \\hat{y}_i \\right) $è¡¨ç¤ºæ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡å‘é‡ä¸­çš„ç¬¬$ \\left( i \\right) $ä¸ªå…ƒç´ ï¼Œ$\\left( y_i \\right) $è¡¨ç¤ºå®é™…çš„ç›®æ ‡æ ‡ç­¾ä¸­çš„ç¬¬$ \\left( i \\right) $ä¸ªå…ƒç´ ã€‚åœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­ï¼Œ$\\left( y_i \\right) $é€šå¸¸æ˜¯0æˆ–1ã€‚è¿™ä¸ªå…¬å¼è¡¨ç¤ºå¯¹æ‰€æœ‰æ ·æœ¬çš„äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±è¿›è¡Œäº†æ±‚å’Œå¹¶å–å¹³å‡ã€‚\n",
    "\n",
    "å› æ­¤BCELossçš„æ‰‹åŠ¨å®ç°å¦‚ä¸‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e31b86ec-4114-48dd-8d73-fe4e0686419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ï¼š\n",
      "tensor([0.6900])\n",
      "æ ‡ç­¾ï¼š\n",
      "tensor([1.])\n",
      "My_BCELossæŸå¤±å€¼: 0.37110066413879395\n",
      "nn.BCELossæŸå¤±å€¼: 0.37110066413879395\n"
     ]
    }
   ],
   "source": [
    "class My_BCELoss:\n",
    "    def __call__(self, prediction: torch.Tensor, target: torch.Tensor):\n",
    "        loss = -torch.mean(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))\n",
    "        return loss\n",
    "\n",
    "\n",
    "# æµ‹è¯•\n",
    "prediction = torch.sigmoid(torch.tensor([0.8]))\n",
    "target = torch.tensor([1.0])\n",
    "print(f\"è¾“å…¥ï¼š\\n{prediction}\")\n",
    "print(f\"æ ‡ç­¾ï¼š\\n{target}\")\n",
    "\n",
    "my_bce_loss = My_BCELoss()\n",
    "my_loss = my_bce_loss(prediction, target)\n",
    "print(\"My_BCELossæŸå¤±å€¼:\", my_loss.item())\n",
    "\n",
    "nn_bce_loss = nn.BCELoss()\n",
    "nn_loss = nn_bce_loss(prediction, target)\n",
    "print(\"nn.BCELossæŸå¤±å€¼:\", nn_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b0300-8808-4c43-9bf9-05a7e6e1f5af",
   "metadata": {},
   "source": [
    "Optimizerçš„å®ç°è¾ƒä¸ºç®€å•ã€‚\n",
    "\n",
    "ä¸»è¦å®ç°ï¼š\n",
    "- ä¼ å…¥å‚æ•°ï¼š`__init__()`\n",
    "- å¯¹ä¼ å…¥çš„å‚æ•°è¿›è¡Œæ›´æ–°ï¼š`step()`\n",
    "- æ¸…ç©ºä¼ å…¥å‚æ•°å­˜å‚¨çš„æ¢¯åº¦ï¼š`zero_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0297066c-9fc1-448d-bdcb-29a6f1519117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.backward()ä¹‹åï¼Œxçš„æ¢¯åº¦:  2.0\n",
      "optimizer_test.step()ä¹‹åï¼Œxçš„å€¼:  0.800000011920929\n",
      "optimizer_test.zero_grad()ä¹‹åï¼Œxçš„æ¢¯åº¦:  0.0\n"
     ]
    }
   ],
   "source": [
    "class My_optimizer:\n",
    "    def __init__(self, params: list[torch.Tensor], lr: float):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.data = param.data - self.lr * param.grad.data\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.zero_()\n",
    "\n",
    "\n",
    "# æµ‹è¯•\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "optimizer_test = My_optimizer([x], lr=0.1)\n",
    "\n",
    "y.backward()\n",
    "print(\"y.backward()ä¹‹åï¼Œxçš„æ¢¯åº¦: \", x.grad.item())\n",
    "\n",
    "optimizer_test.step()\n",
    "print(\"optimizer_test.step()ä¹‹åï¼Œxçš„å€¼: \", x.item())\n",
    "\n",
    "optimizer_test.zero_grad()\n",
    "print(\"optimizer_test.zero_grad()ä¹‹åï¼Œxçš„æ¢¯åº¦: \", x.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab83528-a88b-4d66-b0c9-b1315cf75c22",
   "metadata": {},
   "source": [
    "çº¿æ€§å±‚ä¸»è¦æœ‰ä¸€ä¸ªæƒé‡ï¼ˆweight)å’Œä¸€ä¸ªåç½®ï¼ˆbiasï¼‰ã€‚\n",
    "çº¿æ€§å±‚çš„æ•°å­¦å…¬å¼å¦‚ä¸‹ï¼š\n",
    "$$\n",
    "x:=x \\times weight^T+bias\n",
    "$$\n",
    "å› æ­¤ä»£ç å®ç°å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e18695a-d8c5-4f77-8b5c-de40d9240fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ï¼š\n",
      "tensor([[1.],\n",
      "        [2.]], requires_grad=True)\n",
      "æƒé‡ï¼š\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "åç½®ï¼š\n",
      "tensor([[1.]])\n",
      "My_Linearè¾“å‡ºï¼š\n",
      "tensor([[2., 3., 4.],\n",
      "        [3., 5., 7.]], grad_fn=<AddBackward0>)\n",
      "nn.Linearè¾“å‡ºï¼š\n",
      "tensor([[2., 3., 4.],\n",
      "        [3., 5., 7.]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class My_Linear:\n",
    "    def __init__(self, input_feature: int, output_feature: int):\n",
    "        self.weight = torch.randn((output_feature, input_feature), requires_grad=True, dtype=torch.float32)\n",
    "        self.bias = torch.randn(1, requires_grad=True, dtype=torch.float32)\n",
    "        self.params = [self.weight, self.bias]\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = torch.matmul(x, self.weight.T) + self.bias\n",
    "        return x\n",
    "\n",
    "    def to(self, device: str):\n",
    "        for param in self.params:\n",
    "            param.data = param.data.to(device=device)\n",
    "        return self\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.params\n",
    "\n",
    "        \n",
    "# æµ‹è¯•\n",
    "my_linear = My_Linear(1, 3)\n",
    "nn_linear = nn.Linear(1, 3)\n",
    "weight = torch.nn.Parameter(torch.tensor([[1.],\n",
    "                                          [2.],\n",
    "                                          [3.]]), requires_grad=True)\n",
    "bias = torch.nn.Parameter(torch.tensor([[1.]]), requires_grad=True)\n",
    "nn_linear.weight, my_linear.weight = weight, weight\n",
    "nn_linear.bias, my_linear.bias = bias, bias\n",
    "x = torch.tensor([[1.], [2.]], requires_grad=True)\n",
    "print(f\"è¾“å…¥ï¼š\\n{x}\")\n",
    "print(f\"æƒé‡ï¼š\\n{my_linear.weight.data}\")\n",
    "print(f\"åç½®ï¼š\\n{my_linear.bias.data}\")\n",
    "y_my_linear = my_linear(x)\n",
    "print(f\"My_Linearè¾“å‡ºï¼š\\n{y_my_linear}\")\n",
    "y_nn_linear = nn_linear(x)\n",
    "print(f\"nn.Linearè¾“å‡ºï¼š\\n{y_nn_linear}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff813cc-c1f0-4c73-a3e8-d6796ef5d366",
   "metadata": {},
   "source": [
    "æ‰‹åŠ¨å®ç°logisticå›å½’æ¨¡å‹ã€‚\n",
    "\n",
    "æ¨¡å‹å¾ˆç®€å•ï¼Œä¸»è¦ç”±ä¸€ä¸ªçº¿æ€§å±‚å’Œä¸€ä¸ªsigmoidå±‚ç»„æˆã€‚\n",
    "\n",
    "Sigmoidå‡½æ•°ï¼ˆåˆç§°ä¸º Logisticå‡½æ•°ï¼‰æ˜¯ä¸€ç§å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸ç”¨äºç¥ç»ç½‘ç»œçš„è¾“å‡ºå±‚æˆ–éšè—å±‚ï¼Œå…¶ä½œç”¨æ˜¯å°†è¾“å…¥çš„å®æ•°å€¼å‹ç¼©åˆ°ä¸€ä¸ªèŒƒå›´åœ¨0å’Œ1ä¹‹é—´çš„æ•°å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7de7e4b-a084-4793-812e-46e8550ecd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2_1():\n",
    "    def __init__(self):\n",
    "        self.linear = My_Linear(1, 1)\n",
    "        self.params = self.linear.params\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def to(self, device: str):\n",
    "        for param in self.params:\n",
    "            param.data = param.data.to(device=device)\n",
    "        return self\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14acea9-e5ef-4c24-aea9-329647224ce1",
   "metadata": {},
   "source": [
    "äººå·¥éšæœºæ„é€ æ•°æ®é›†ã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘é‡åˆ°äº†æ¯”è¾ƒå¤§çš„é—®é¢˜ã€‚å› ä¸ºæ•°æ®æ„å»ºä¸åˆé€‚ï¼Œä¼šå¯¼è‡´åé¢çš„è®­ç»ƒå‡ºç°æ¢¯åº¦çˆ†ç‚¸ã€‚\n",
    "\n",
    "æˆ‘é‡‡ç”¨éšæœºäº§ç”Ÿæ•°æ®åå½’ä¸€åŒ–çš„æ–¹æ³•ï¼Œå³\n",
    "$$\n",
    "\\hat{x} = \\frac{x - \\text{min}_x}{\\text{max}_x - \\text{min}_x} \n",
    "$$\n",
    "å°†æ•°æ®æ§åˆ¶åœ¨åˆé€‚çš„åŒºé—´ã€‚\n",
    "\n",
    "æˆ‘çš„yè®¾ç½®ä¸º$4-3\\times x + noise$ï¼Œnoiseä¸ºéšæœºå™ªå£°ã€‚\n",
    "\n",
    "ç”Ÿæˆå®Œxå’Œyåè¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œå¹¶å†™å¥½DataLoaderè®¿é—®æ•°æ®é›†çš„æ¥å£`__getitem__()`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c39fbafb-62e4-4b8c-9d65-6718d25f2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•æ•°æ®é›†å¤§å°ï¼š1000000\n",
      "æµ‹è¯•æ•°æ®é›†ç¬¬0å¯¹æ•°æ®ï¼š\n",
      "x_0 = 0.5488133381316141\n",
      "y_0 = 0.45217091576438073\n"
     ]
    }
   ],
   "source": [
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, data_size=1000000):\n",
    "        np.random.seed(0)\n",
    "        x = 2 * np.random.rand(data_size, 1)\n",
    "        noise = 0.2 * np.random.randn(data_size, 1)\n",
    "        y = 4 - 3 * x + noise\n",
    "        self.min_x, self.max_x = np.min(x), np.max(x)\n",
    "        min_y, max_y = np.min(y), np.max(y)\n",
    "        x = (x - self.min_x) / (self.max_x - self.min_x)\n",
    "        y = (y - min_y) / (max_y - min_y)\n",
    "        self.data = [[x[i][0], y[i][0]] for i in range(x.shape[0])]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.data[index]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# æµ‹è¯•ï¼Œå¹¶åé¢çš„è®­ç»ƒåˆ›å»ºå˜é‡\n",
    "dataset = My_Dataset()\n",
    "dataset_size = len(dataset)\n",
    "print(f\"æµ‹è¯•æ•°æ®é›†å¤§å°ï¼š{dataset_size}\")\n",
    "x0, y0 = dataset[0]\n",
    "print(f\"æµ‹è¯•æ•°æ®é›†ç¬¬0å¯¹æ•°æ®ï¼š\")\n",
    "print(f\"x_0 = {x0}\")\n",
    "print(f\"y_0 = {y0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a76a2-b306-47a8-912e-8fbf00cdfd42",
   "metadata": {},
   "source": [
    "è®­ç»ƒLogisticå›å½’æ¨¡å‹ã€‚\n",
    "è¿›è¡Œå¦‚ä¸‹æ­¥éª¤ï¼š\n",
    "1. åˆå§‹åŒ–è¶…å‚æ•°\n",
    "2. è·å–æ•°æ®é›†\n",
    "3. åˆå§‹åŒ–æ¨¡å‹\n",
    "4. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "5. è®­ç»ƒ\n",
    "    1. ä»è®­ç»ƒdataloaderä¸­è·å–æ‰¹é‡æ•°æ®\n",
    "    2. ä¼ å…¥æ¨¡å‹\n",
    "    3. ä½¿ç”¨æŸå¤±å‡½æ•°è®¡ç®—ä¸ground_truthçš„æŸå¤±\n",
    "    4. ä½¿ç”¨ä¼˜åŒ–å™¨è¿›è¡Œåå‘ä¼ æ’­\n",
    "    5. å¾ªç¯ä»¥ä¸Šæ­¥éª¤\n",
    "6. æµ‹è¯•\n",
    "    1. è®¾ç½®æµ‹è¯•æ•°æ®\n",
    "    2. ä¼ å…¥æ¨¡å‹\n",
    "    3. å¾—åˆ°é¢„æµ‹å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5612661e-2809-4d46-96c2-33ee9f44116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 681.7797573804855, Acc: 0.9645753421871553\n",
      "Epoch 2/10, Loss: 677.2049961090088, Acc: 0.9990700532071279\n",
      "Epoch 3/10, Loss: 677.1804099082947, Acc: 0.9996768410577491\n",
      "Epoch 4/10, Loss: 677.175698697567, Acc: 0.9996360650992927\n",
      "Epoch 5/10, Loss: 677.1747546195984, Acc: 0.999986148984189\n",
      "Epoch 6/10, Loss: 677.1744914650917, Acc: 0.9998796786709696\n",
      "Epoch 7/10, Loss: 677.1742819547653, Acc: 0.9999521451026462\n",
      "Epoch 8/10, Loss: 677.1738398075104, Acc: 0.9999777880946412\n",
      "Epoch 9/10, Loss: 677.1740134358406, Acc: 0.9997993523341308\n",
      "Epoch 10/10, Loss: 677.1745718121529, Acc: 0.9998104022783462\n",
      "Model weights: -0.0036095045506954193, bias: 0.016485782340168953\n",
      "Prediction for test data: 0.5032190084457397\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-2\n",
    "num_epochs = 10\n",
    "batch_size = 1024\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "model = Model_2_1().to(device)\n",
    "criterion = My_BCELoss()\n",
    "optimizer = My_optimizer(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_pred = 0\n",
    "    total_epoch_target = 0\n",
    "    for x, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(device).to(dtype=torch.float32)\n",
    "        targets = targets.to(device).to(dtype=torch.float32)\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, targets)\n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_target += targets.sum().item()\n",
    "        total_epoch_pred += y_pred.sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_epoch_loss}, \", end=\"\")\n",
    "    print(f\"Acc: {1 - abs(total_epoch_pred - total_epoch_target) / total_epoch_target}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_data = (np.array([[2]]) - dataset.min_x) / (dataset.max_x - dataset.min_x)\n",
    "    test_data = Variable(torch.tensor(test_data, dtype=torch.float32), requires_grad=False).to(device)\n",
    "    predicted = model(test_data).to(\"cpu\")\n",
    "    print(f\"Model weights: {model.linear.weight.item()}, bias: {model.linear.bias.item()}\")\n",
    "    print(f\"Prediction for test data: {predicted.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e416582-a30d-4084-acc6-6e05f80a6aff",
   "metadata": {},
   "source": [
    "## é¢˜ç›®2\n",
    "**åˆ©ç”¨ torch.nn å®ç° logistic å›å½’åœ¨äººå·¥æ„é€ çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œåˆ†æï¼Œå¹¶ä»lossä»¥åŠè®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ç­‰å¤šä¸ªè§’åº¦å¯¹ç»“æœè¿›è¡Œåˆ†æ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0460d125-7d03-44fe-845c-c4d13792e241",
   "metadata": {},
   "source": [
    "ä½¿ç”¨torch.nnå®ç°æ¨¡å‹ã€‚\n",
    "\n",
    "å°†ä¹‹å‰çš„Model_2_1ä¸­çš„æ‰‹åŠ¨å®ç°å‡½æ•°æ”¹ä¸ºtorch.nnå†…ç½®å‡½æ•°å³å¯ï¼Œå†åŠ ä¸Šç»§æ‰¿nn.Moduleä»¥ä½¿ç”¨torch.nnå†…ç½®æ¨¡å‹æ¨¡æ¿ç‰¹æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa121afd-a1af-4193-9b54-68041e0ed068",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_2_2, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176eee7e-4e3d-470e-8af2-8761bca039f8",
   "metadata": {},
   "source": [
    "è®­ç»ƒä¸æµ‹è¯•è¿‡ç¨‹ä¸ä¹‹å‰æ‰‹åŠ¨å®ç°çš„å‡ ä¹ä¸€è‡´ã€‚ä»…æœ‰å°‘é‡æ¶‰åŠæ•°æ®ç±»å‹ï¼ˆdtypeï¼‰çš„ä»£ç éœ€è¦æ›´æ”¹ä»¥é€‚åº”torch.nnçš„å†…ç½®å‡½æ•°è¦æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93b0fdb6-be8b-4663-b59e-05ed19a9ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 582.1114150944223, Acc: 0.9622313076669672\n",
      "Epoch 2/10, Loss: 565.93256158834, Acc: 0.9999686256703629\n",
      "Epoch 3/10, Loss: 565.9305296230643, Acc: 0.9999988205402547\n",
      "Epoch 4/10, Loss: 565.9292865398384, Acc: 0.9999988799203948\n",
      "Epoch 5/10, Loss: 565.928863850198, Acc: 0.9999991768121363\n",
      "Epoch 6/10, Loss: 565.9304914128694, Acc: 0.9999969140456769\n",
      "Epoch 7/10, Loss: 565.9264041730053, Acc: 0.9999955753695261\n",
      "Epoch 8/10, Loss: 565.9313891761873, Acc: 0.9999980937154029\n",
      "Epoch 9/10, Loss: 565.9266170542029, Acc: 0.9999949410275989\n",
      "Epoch 10/10, Loss: 565.9337094448973, Acc: 0.9999975812010478\n",
      "Model weights: -3.7012964947839575, bias: 1.8774806436910758\n",
      "Prediction for test data: 0.13897650708244993\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "num_epochs = 10\n",
    "batch_size = 1024\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "model = Model_2_2().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_pred = 0\n",
    "    total_epoch_target = 0\n",
    "    for x, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        targets = targets.unsqueeze(1)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, targets)\n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_target += targets.sum().item()\n",
    "        total_epoch_pred += y_pred.sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_epoch_loss}, \", end=\"\")\n",
    "    print(f\"Acc: {1 - abs(total_epoch_pred - total_epoch_target) / total_epoch_target}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_data = (np.array([[2]]) - dataset.min_x) / (dataset.max_x - dataset.min_x)\n",
    "    test_data = Variable(torch.tensor(test_data, dtype=torch.float64), requires_grad=False).to(device)\n",
    "    predicted = model(test_data).to(\"cpu\")\n",
    "    print(f\"Model weights: {model.linear.weight.item()}, bias: {model.linear.bias.item()}\")\n",
    "    print(f\"Prediction for test data: {predicted.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bff679-f8d2-46cc-bdcb-82af7dab38b3",
   "metadata": {},
   "source": [
    "å¯¹æ¯”å‘ç°ï¼Œä½¿ç”¨torch.nnçš„å†…ç½®æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼Œæ­£ç¡®ç‡æå‡æ›´å¿«ã€‚\n",
    "\n",
    "ä½†æ˜¯ä¸ºä»€ä¹ˆç›¸åŒåˆ†å¸ƒçš„æ•°æ®é›†è®­ç»ƒå‡ºçš„æƒé‡å’Œåç½®ï¼Œä»¥åŠé¢„æµ‹ç»“æœå­˜åœ¨è¾ƒå¤§å·®åˆ«ï¼Œè¿™ä¸ªé—®é¢˜çš„åŸå› è¿˜æœ‰å¾…æˆ‘æ¢ç©¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41d7fa-c2bf-4024-833b-60af0a87043a",
   "metadata": {},
   "source": [
    "# ä¸‰ã€åŠ¨æ‰‹å®ç°softmaxå›å½’\n",
    "\n",
    "## é—®é¢˜1\n",
    "\n",
    "**è¦æ±‚åŠ¨æ‰‹ä»0å®ç°softmaxå›å½’ï¼ˆåªå€ŸåŠ©Tensorå’ŒNumpyç›¸å…³çš„åº“ï¼‰åœ¨Fashion-MNISTæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå¹¶ä»lossã€è®­ç»ƒé›†ä»¥åŠæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ç­‰å¤šä¸ªè§’åº¦å¯¹ç»“æœè¿›è¡Œåˆ†æï¼ˆè¦æ±‚ä»é›¶å®ç°äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼‰**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c356760-75a8-4814-ba69-73b270396a4e",
   "metadata": {},
   "source": [
    "æ‰‹åŠ¨å®ç°nn.one_hot()ã€‚\n",
    "\n",
    "one-hotå‘é‡ç”¨äºæ¶ˆé™¤çº¿æ€§æ ‡ç­¾å€¼æ‰€æ˜ å°„çš„ç±»åˆ«çš„éçº¿æ€§ã€‚\n",
    "\n",
    "one-hotå‘é‡æ˜¯ä½¿ç”¨ä¸€ä¸ªé•¿åº¦ä¸ºåˆ†ç±»æ•°é‡çš„æ•°ç»„è¡¨ç¤ºæ ‡ç­¾å€¼ï¼Œå…¶ä¸­æœ‰ä¸”ä»…æœ‰1ä¸ªå€¼ä¸ºä¸º1ï¼Œè¯¥å€¼çš„ä¸‹æ ‡ä¸ºæ ‡ç­¾å€¼ï¼›å…¶ä½™ä¸º0ã€‚\n",
    "\n",
    "åŸç†å¾ˆç®€å•ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š\n",
    "1. åˆå§‹åŒ–å…¨é›¶çš„å¼ é‡ï¼Œå¤§å°ä¸ºï¼ˆæ ‡ç­¾æ•°é‡ï¼Œåˆ†ç±»æ•°é‡ï¼‰ï¼›\n",
    "2. å°†æ ‡ç­¾å€¼æ˜ å°„åˆ°å…¨é›¶å¼ é‡çš„\\[ä¸‹æ ‡ï¼Œæ ‡ç­¾å€¼\\]ä¸­ï¼Œå°†è¯¥ä½ç½®ä¸º1ï¼›\n",
    "3. è¿”å›ä¿®æ”¹åçš„å¼ é‡ï¼Œå³æ˜¯ont-hotå‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e605f1b0-1d32-410f-bddf-402a85ccc9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ï¼š\n",
      "tensor([2, 1, 0])\n",
      "my_one_hotè¾“å‡ºï¼š\n",
      "tensor([[0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0]])\n",
      "nn.functional.one_hotè¾“å‡ºï¼š\n",
      "tensor([[0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "def my_one_hot(indices: torch.Tensor, num_classes: int):\n",
    "    one_hot_tensor = torch.zeros(len(indices), num_classes).to(indices.device).to(dtype=torch.int64)\n",
    "    one_hot_tensor.scatter_(1, indices.view(-1, 1), 1)\n",
    "    return one_hot_tensor\n",
    "\n",
    "\n",
    "# æµ‹è¯•\n",
    "x = torch.tensor([2, 1, 0], dtype=torch.int64)\n",
    "print(f\"è¾“å…¥ï¼š\\n{x}\")\n",
    "\n",
    "x_my_onehot = my_one_hot(x, 5)\n",
    "print(f\"my_one_hotè¾“å‡ºï¼š\\n{x_my_onehot}\")\n",
    "\n",
    "x_nn_F_onehot = nn.functional.one_hot(x, 5)\n",
    "print(f\"nn.functional.one_hotè¾“å‡ºï¼š\\n{x_nn_F_onehot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902603a6-bfb9-4ce3-bd0d-b00cebb1d3cb",
   "metadata": {},
   "source": [
    "æ‰‹åŠ¨å®ç°CrossEntropyLossã€‚\n",
    "\n",
    "CrossEntropyLossç”±ä¸€ä¸ªlog_softmaxå’Œä¸€ä¸ªnll_lossç»„æˆã€‚\n",
    "\n",
    "softmaxçš„æ•°å­¦è¡¨è¾¾å¼å¦‚ä¸‹ï¼š\n",
    "$$\n",
    "\\text{softmax}(y_i) = \\frac{e^{y_i - \\text{max}(y)}}{\\sum_{j=1}^{N} e^{y_j - \\text{max}(y)}} \n",
    "$$\n",
    "log_softmaxå³ä¸º$\\log\\left(softmax\\left(y\\right)\\right)$ã€‚\n",
    "\n",
    "CrossEntropyLossçš„æ•°å­¦è¡¨è¾¾å¼å¦‚ä¸‹ï¼š\n",
    "$$\n",
    "\\text{CrossEntropyLoss}(y, \\hat{y}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\hat{y}_i \\cdot \\log(\\text{softmax}(y_i)) \n",
    "$$\n",
    "\n",
    "æ•…ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "759a3bb2-b5f4-4ea5-a2d7-15f0c4cdd14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥ï¼š\n",
      "tensor([[ 0.4113,  1.0890, -0.4301, -0.1975,  2.2331],\n",
      "        [ 0.7901,  1.8117, -2.3197, -0.8144, -0.5751],\n",
      "        [-1.8110, -0.5550, -0.2773,  2.3990,  0.1804]], requires_grad=True)\n",
      "æ ‡ç­¾ï¼š\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "My_CrossEntropyLossæŸå¤±å€¼: 1.1033374071121216\n",
      "nn.CrossEntropyLossæŸå¤±å€¼: 1.1033374071121216\n"
     ]
    }
   ],
   "source": [
    "class My_CrossEntropyLoss:\n",
    "    def __call__(self, predictions: torch.Tensor, targets: torch.Tensor):\n",
    "        max_values = torch.max(predictions, dim=1, keepdim=True).values\n",
    "        exp_values = torch.exp(predictions - max_values)\n",
    "        softmax_output = exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
    "        log_probs = torch.log(softmax_output)\n",
    "        \n",
    "        nll_loss = -torch.sum(targets * log_probs, dim=1)\n",
    "        average_loss = torch.mean(nll_loss)\n",
    "        return average_loss\n",
    "\n",
    "        \n",
    "# æµ‹è¯•\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1).argmax(1)\n",
    "target = torch.nn.functional.one_hot(target, num_classes=5).to(dtype=torch.float32)\n",
    "print(f\"è¾“å…¥ï¼š\\n{input}\")\n",
    "print(f\"æ ‡ç­¾ï¼š\\n{target}\")\n",
    "\n",
    "my_crossentropyloss = My_CrossEntropyLoss()\n",
    "my_loss = my_crossentropyloss(input, target)\n",
    "print(\"My_CrossEntropyLossæŸå¤±å€¼:\", my_loss.item())\n",
    "\n",
    "nn_crossentropyloss = nn.CrossEntropyLoss()\n",
    "nn_loss = nn_crossentropyloss(input, target)\n",
    "print(\"nn.CrossEntropyLossæŸå¤±å€¼:\", nn_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf78501-f5be-4008-986c-d331d531491f",
   "metadata": {},
   "source": [
    "æ‰‹åŠ¨å®ç°Flattenã€‚\n",
    "\n",
    "åŸç†å¾ˆç®€å•ï¼Œå°±æ˜¯æŠŠå¤šç»´çš„å¼ é‡æ‹‰ç›´æˆä¸€ä¸ªå‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74322629-8325-4823-b80f-f28182d577c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattenä¹‹å‰çš„xï¼š\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n",
      "My_Flattenä¹‹åçš„xï¼š\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n",
      "nn.Flattenä¹‹åçš„xï¼š\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "class My_Flatten:\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# æµ‹è¯•\n",
    "my_flatten = My_Flatten()\n",
    "nn_flatten = nn.Flatten()\n",
    "x = torch.tensor([[[1., 2.],\n",
    "                   [3., 4.]],\n",
    "                  [[5., 6.],\n",
    "                   [7., 8.]]])\n",
    "print(f\"Flattenä¹‹å‰çš„xï¼š\\n{x}\")\n",
    "x_my_flatten = my_flatten(x)\n",
    "print(f\"My_Flattenä¹‹åçš„xï¼š\\n{x_my_flatten}\")\n",
    "x_nn_flatten = nn_flatten(x)\n",
    "print(f\"nn.Flattenä¹‹åçš„xï¼š\\n{x_nn_flatten}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aee905-ae37-4faa-a7f1-a04cd8579f78",
   "metadata": {},
   "source": [
    "æ‰‹åŠ¨å®ç°softmaxå›å½’æ¨¡å‹ã€‚\n",
    "\n",
    "æ¨¡å‹å¾ˆç®€å•ï¼Œä¸»è¦ç”±ä¸€ä¸ªFlattenå±‚å’Œä¸€ä¸ªçº¿æ€§å±‚ç»„æˆã€‚\n",
    "\n",
    "Flattenå±‚ä¸»è¦ç”¨äºå°†2ç»´çš„å›¾åƒå±•å¼€ï¼Œç›´æ¥ä½œä¸º1ç»´çš„ç‰¹å¾é‡è¾“å…¥ç½‘ç»œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb31a75e-464c-4b94-b927-b219a765e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_3_1:\n",
    "    def __init__(self, num_classes):\n",
    "        self.flatten = My_Flatten()\n",
    "        self.linear = My_Linear(28 * 28, num_classes)\n",
    "        self.params = self.linear.params\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def to(self, device: str):\n",
    "        for param in self.params:\n",
    "            param.data = param.data.to(device=device)\n",
    "        return self\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e686d1-9c9a-4727-8fdc-9990d348c523",
   "metadata": {},
   "source": [
    "è®­ç»ƒä¸æµ‹è¯•è¿‡ç¨‹ä¸ä¹‹å‰æ‰‹åŠ¨å®ç°çš„å‡ ä¹ä¸€è‡´ã€‚ç”±äºæ•°æ®é›†çš„å˜åŒ–ï¼Œå¯¹åº”è¶…å‚æ•°ä¹Ÿè¿›è¡Œäº†è°ƒæ•´ã€‚\n",
    "\n",
    "æ•°æ®é›†ä¹Ÿä½¿ç”¨äº†ç°æˆçš„FashionMNISTæ•°æ®é›†ï¼Œä¸”åˆ’åˆ†äº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚\n",
    "\n",
    "FashionMNISTæ•°æ®é›†ç›´æ¥è°ƒç”¨APIè·å–ã€‚æ•°æ®é›†çš„imageä¸º28*28çš„å•é€šé“ç°ç™½å›¾ç‰‡ï¼Œlabelä¸ºå•ä¸ªæ•°å€¼æ ‡ç­¾ã€‚\n",
    "\n",
    "è®­ç»ƒsoftmaxå›å½’æ¨¡å‹ã€‚\n",
    "è¿›è¡Œå¦‚ä¸‹æ­¥éª¤ï¼š\n",
    "1. åˆå§‹åŒ–è¶…å‚æ•°\n",
    "2. è·å–æ•°æ®é›†\n",
    "3. åˆå§‹åŒ–æ¨¡å‹\n",
    "4. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "5. è®­ç»ƒ\n",
    "    1. ä»è®­ç»ƒdataloaderä¸­è·å–æ‰¹é‡æ•°æ®\n",
    "    2. ä¼ å…¥æ¨¡å‹\n",
    "    3. ä½¿ç”¨æŸå¤±å‡½æ•°è®¡ç®—ä¸ground_truthçš„æŸå¤±\n",
    "    4. ä½¿ç”¨ä¼˜åŒ–å™¨è¿›è¡Œåå‘ä¼ æ’­\n",
    "    5. å¾ªç¯ä»¥ä¸Šæ­¥éª¤\n",
    "6. æµ‹è¯•\n",
    "    1. ä»æµ‹è¯•dataloaderä¸­è·å–æ‰¹é‡æ•°æ®\n",
    "    2. ä¼ å…¥æ¨¡å‹\n",
    "    3. å°†é¢„æµ‹å€¼ä¸ground_truthè¿›è¡Œæ¯”è¾ƒï¼Œå¾—å‡ºæ­£ç¡®ç‡\n",
    "    4. å¯¹æ•´ä¸ªè®­ç»ƒé›†ç»Ÿè®¡æ­£ç¡®ç‡ï¼Œä»è€Œåˆ†æè®­ç»ƒæ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d816dae1-5fbe-4c29-9597-19d66b5eb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 2/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 3/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 4/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 5/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 6/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 7/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 8/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 9/10, Loss: nan, Acc: 0.09999999403953552\n",
      "Epoch 10/10, Loss: nan, Acc: 0.09999999403953552\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-3\n",
    "num_epochs = 10\n",
    "batch_size = 4096\n",
    "num_classes = 10\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = datasets.FashionMNIST(root=\"./dataset\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./dataset\", train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = Model_3_1(num_classes).to(device)\n",
    "criterion = My_CrossEntropyLoss()\n",
    "optimizer = My_optimizer(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss = 0\n",
    "    for images, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device).to(dtype=torch.long)\n",
    "\n",
    "        one_hot_targets = my_one_hot(targets, num_classes=num_classes).to(device).to(dtype=torch.long)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, one_hot_targets)\n",
    "        total_epoch_loss += loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for image, targets in test_loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(image)\n",
    "            total_acc += (outputs.argmax(1) == targets).sum()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_epoch_loss}, Acc: {total_acc / len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d0165-aeb7-48c0-9b67-956bb08cb356",
   "metadata": {},
   "source": [
    "è¿™é‡Œå‘ç°æ¢¯åº¦çˆ†ç‚¸ã€‚æš‚æ—¶æ— æ³•è§£å†³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5240f-8a11-4678-bfce-f1cbc7e71b77",
   "metadata": {},
   "source": [
    "## é—®é¢˜2\n",
    "\n",
    "**åˆ©ç”¨torch.nnå®ç°softmaxå›å½’åœ¨Fashion-MNISTæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå¹¶ä»lossï¼Œè®­ç»ƒé›†ä»¥åŠæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ç­‰å¤šä¸ªè§’åº¦å¯¹ç»“æœè¿›è¡Œåˆ†æ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a88c6-637e-4af5-bed5-f644685dcabc",
   "metadata": {},
   "source": [
    "ä½¿ç”¨torch.nnå®ç°æ¨¡å‹ã€‚\n",
    "\n",
    "å°†ä¹‹å‰çš„Model_3_1ä¸­çš„æ‰‹åŠ¨å®ç°å‡½æ•°æ”¹ä¸ºtorch.nnå†…ç½®å‡½æ•°å³å¯ï¼Œå†åŠ ä¸Šç»§æ‰¿nn.Moduleä»¥ä½¿ç”¨torch.nnå†…ç½®æ¨¡å‹æ¨¡æ¿ç‰¹æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0163b9f7-1019-429c-8c29-06436d0a4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_3_2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Model_3_2, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(28 * 28, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e765ad7-c1c6-4166-bd7f-361666bd4016",
   "metadata": {},
   "source": [
    "è®­ç»ƒä¸æµ‹è¯•è¿‡ç¨‹ä¸ä¹‹å‰æ‰‹åŠ¨å®ç°çš„å‡ ä¹ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a58a23e1-368c-430a-ad62-0e256dff564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 15.768913269042969, Acc: 0.7530999779701233\n",
      "Epoch 2/10, Loss: 9.122207641601562, Acc: 0.7967000007629395\n",
      "Epoch 3/10, Loss: 7.9603657722473145, Acc: 0.8100999593734741\n",
      "Epoch 4/10, Loss: 7.427120208740234, Acc: 0.8179000020027161\n",
      "Epoch 5/10, Loss: 7.115703582763672, Acc: 0.8248999714851379\n",
      "Epoch 6/10, Loss: 6.900459289550781, Acc: 0.8259999752044678\n",
      "Epoch 7/10, Loss: 6.802896976470947, Acc: 0.8269000053405762\n",
      "Epoch 8/10, Loss: 6.687209606170654, Acc: 0.832099974155426\n",
      "Epoch 9/10, Loss: 6.6183180809021, Acc: 0.833299994468689\n",
      "Epoch 10/10, Loss: 6.531178951263428, Acc: 0.8341999650001526\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-3\n",
    "num_epochs = 10\n",
    "batch_size = 4096\n",
    "num_classes = 10\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = datasets.FashionMNIST(root=\"./dataset\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./dataset\", train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = Model_3_2(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss = 0\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        one_hot_targets = nn.functional.one_hot(targets, num_classes=num_classes).to(device).to(dtype=torch.float32)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, one_hot_targets)\n",
    "        total_epoch_loss += loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for image, targets in test_loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(image)\n",
    "            total_acc += (outputs.argmax(1) == targets).sum()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_epoch_loss}, Acc: {total_acc / len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59555b67-1650-4e1a-a98e-7906878bf3d0",
   "metadata": {},
   "source": [
    "ä¸æ‰‹åŠ¨å®ç°çš„softmaxå›å½’ç›¸æ¯”è¾ƒï¼Œnn.CrossEntropyLossæ¯”æ‰‹åŠ¨å®ç°çš„My_CrossEntropyLossæ›´åŠ ç¨³å®šï¼Œæ²¡æœ‰å‡ºç°æ¢¯åº¦çˆ†ç‚¸çš„æƒ…å†µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40431f2-e77b-4ead-81a3-ff6451a8e452",
   "metadata": {},
   "source": [
    "**å®éªŒå¿ƒå¾—ä½“ä¼š**\n",
    "\n",
    "é€šè¿‡å®Œæˆæœ¬æ¬¡PytorchåŸºæœ¬æ“ä½œå®éªŒï¼Œè®©æˆ‘å¯¹Pytorchæ¡†æ¶æœ‰äº†æ›´åŠ æ·±å…¥çš„ç†è§£ã€‚æˆ‘æ¥è§¦æ·±åº¦å­¦ä¹ ä¸»è¦æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹é¢†åŸŸï¼Œæ¯”è¾ƒç†Ÿæ‚‰å¾®è°ƒå¤§æ¨¡å‹ï¼Œä½†æ˜¯æ¶‰åŠåˆ°åº•å±‚çš„æ·±åº¦å­¦ä¹ çŸ¥è¯†ï¼Œæˆ‘è¿˜æœ‰å¾ˆå¤šçŸ­æ¿å’Œä¸è¶³ã€‚è¿™æ¬¡å®éªŒå¯¹æˆ‘è¿™æ–¹é¢çš„é”»ç‚¼è®©æˆ‘æ”¶è·è‰¯å¤šã€‚\n",
    "\n",
    "é¦–å…ˆæ˜¯æ•°æ®é›†çš„è®¾ç½®ã€‚å¦‚æœæ•°æ®æ²¡æœ‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¾ˆå®¹æ˜“å‡ºç°æ¢¯åº¦çˆ†ç‚¸ã€‚è¿™æ˜¯åœ¨æˆ‘ä»¥å‰ç›´æ¥ä½¿ç”¨å›¾ç‰‡æ•°æ®é›†çš„ç»å†ä¸­æ²¡æœ‰é‡åˆ°è¿‡çš„é—®é¢˜ã€‚\n",
    "\n",
    "åœ¨å®ç°logisticå›å½’æ¨¡å‹æ—¶ï¼Œé€šè¿‡æ‰‹åŠ¨å®ç°å„ä¸ªç»„ä»¶å¦‚ä¼˜åŒ–å™¨ã€çº¿æ€§å±‚ç­‰ï¼Œè®©æˆ‘å¯¹è¿™äº›æ¨¡å—çš„å·¥ä½œåŸç†æœ‰äº†æ›´æ¸…æ™°çš„è®¤è¯†ã€‚å°¤å…¶æ˜¯åœ¨å®ç°å¹¿æ’­æœºåˆ¶æ—¶ï¼Œéœ€è¦å……åˆ†ç†è§£å¼ é‡æ“ä½œçš„ç»´åº¦å˜æ¢è§„å¾‹ã€‚è€Œä½¿ç”¨Pytorchå†…ç½®æ¨¡å—è¿›è¡Œå®ç°æ—¶ï¼Œé€šè¿‡ç»§æ‰¿nn.Moduleå¯ä»¥è‡ªåŠ¨è·å¾—è®¸å¤šåŠŸèƒ½ï¼Œä½¿ä»£ç æ›´åŠ ç®€æ´ã€‚\n",
    "\n",
    "åœ¨å®ç°softmaxå›å½’æ—¶ï¼Œåˆ™é‡åˆ°äº†æ›´å¤§çš„å›°éš¾ã€‚æ‰‹åŠ¨å®ç°çš„æ¨¡å‹å¾ˆå®¹æ˜“å‡ºç°æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼Œè€Œä½¿ç”¨Pytorchå†…ç½®çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨åˆ™å¯ä»¥ç¨³å®šè®­ç»ƒã€‚è¿™è®©æˆ‘æ„è¯†åˆ°äº†é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–æ–¹æ³•çš„é‡è¦æ€§ã€‚å¦å¤–ï¼ŒPytorchå¼ºå¤§çš„è‡ªåŠ¨å¾®åˆ†æœºåˆ¶ä¹Ÿæ˜¯æ„å»ºæ·±åº¦ç¥ç»ç½‘ç»œçš„é‡è¦åŸºç¡€ã€‚\n",
    "\n",
    "é€šè¿‡è¿™ä¸ªå®éªŒï¼Œè®©æˆ‘å¯¹Pytorchæ¡†æ¶æœ‰äº†æ›´åŠ ç›´è§‚çš„æ„Ÿå—ï¼Œä¹Ÿè®©æˆ‘çœ‹åˆ°äº†ä»…é åŸºç¡€æ¨¡å—æ­å»ºå¤æ‚æ¨¡å‹çš„éš¾ç‚¹æ‰€åœ¨ã€‚è¿™äº›ç»éªŒå¯¹æˆ‘åç»­ä½¿ç”¨Pytorchæ„å»ºæ•°æ®é›†æ¨¡å‹ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
